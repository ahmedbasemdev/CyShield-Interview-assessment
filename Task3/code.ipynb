{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting semantic_search.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile semantic_search.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rake_nltk import Rake\n",
    "from helper import *\n",
    "\n",
    "class SemanticSearchManager:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.rake = Rake()\n",
    "    \n",
    "    def insert_date(self, texts:list[str]):\n",
    "        self.data = pd.DataFrame({\"article\": texts})\n",
    "        self.data['article'] = self.data['article'].apply(self.text_preprocessing)\n",
    "        self.data['key_words'] = self.data['article'].apply(self.extract_keywords)\n",
    "        self.embeddings = self.model.encode(self.data['article'].to_list(), convert_to_tensor=True)\n",
    "        \n",
    "\n",
    "    def text_preprocessing(self, text):\n",
    "        text = remove_punctuations(text)\n",
    "        text = remove_digits(text)\n",
    "        text = remove_links(text)\n",
    "        text = remove_hashtags_mentions(text)\n",
    "        return text\n",
    "    \n",
    "    def similarity_search(self, query:str, top_k:int = 3):\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        similarities = util.pytorch_cos_sim(query_embedding, self.embeddings)\n",
    "        top_results = similarities.topk(k=top_k)\n",
    "        results = []\n",
    "        for idx in top_results[1].tolist()[0]:\n",
    "            results.append({\"article\":self.data.iloc[idx].article, \"key_words\":self.data.iloc[idx].key_words})\n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def extract_keywords(self, text):\n",
    "        self.rake.extract_keywords_from_text(text)\n",
    "        return self.rake.get_ranked_phrases()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Ahmed-\n",
      "[nltk_data]     Basem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    \"Artificial Intelligence is revolutionizing technology.\",\n",
    "    \"Climate change is a pressing global issue.\",\n",
    "    \"Advances in quantum computing are remarkable.\",\n",
    "    \"Vaccines are crucial for combating pandemics.\",\n",
    "    \"Space exploration inspires innovation.\"\n",
    "]\n",
    "data = pd.DataFrame({\"article\": articles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "  punctuation = string.punctuation\n",
    "  text = text.translate(str.maketrans(\"\",\"\",punctuation))\n",
    "  return text\n",
    "\n",
    "def remove_digits(text):\n",
    "  digits = string.digits\n",
    "  text = text.translate(str.maketrans(\"\",\"\",digits))\n",
    "  return text\n",
    "\n",
    "def remove_links(text):\n",
    "  text = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)\",\"\",text)\n",
    "  return text\n",
    "\n",
    "def remove_hashtags_mentions(text):\n",
    "  text = re.sub(r\"@[\\w]+\",\"\",text)\n",
    "  text = re.sub(r\"#\\S+\",\"\",text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_digits(text)\n",
    "    text = remove_links(text)\n",
    "    text = remove_hashtags_mentions(text)\n",
    "    return text\n",
    "data['article'] = data['article'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(data['article'].to_list(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake = Rake()\n",
    "\n",
    "def extract_keywords(text):\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    return rake.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['key_words'] = data['article'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence is revolutionizing tec...</td>\n",
       "      <td>[revolutionizing technology, artificial intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Climate change is a pressing global issue.</td>\n",
       "      <td>[pressing global issue, climate change]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advances in quantum computing are remarkable.</td>\n",
       "      <td>[quantum computing, remarkable, advances]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vaccines are crucial for combating pandemics.</td>\n",
       "      <td>[combating pandemics, vaccines, crucial]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Space exploration inspires innovation.</td>\n",
       "      <td>[space exploration inspires innovation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article                                          key_words\n",
       "0  Artificial Intelligence is revolutionizing tec...  [revolutionizing technology, artificial intell...\n",
       "1         Climate change is a pressing global issue.            [pressing global issue, climate change]\n",
       "2      Advances in quantum computing are remarkable.          [quantum computing, remarkable, advances]\n",
       "3      Vaccines are crucial for combating pandemics.           [combating pandemics, vaccines, crucial]\n",
       "4             Space exploration inspires innovation.            [space exploration inspires innovation]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(query:str, top_k:int = 3):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, embeddings)\n",
    "    top_results = similarities.topk(k=top_k)\n",
    "    results = []\n",
    "    for idx in top_results[1].tolist()[0]:\n",
    "        results.append({\"article\":data.iloc[idx].article, \"key_words\":data.iloc[idx].key_words})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search Results: [{'article': 'Artificial Intelligence is revolutionizing technology.', 'key_words': ['revolutionizing technology', 'artificial intelligence']}, {'article': 'Space exploration inspires innovation.', 'key_words': ['space exploration inspires innovation']}, {'article': 'Advances in quantum computing are remarkable.', 'key_words': ['quantum computing', 'remarkable', 'advances']}]\n"
     ]
    }
   ],
   "source": [
    "query = \"technology and AI\"\n",
    "results = similarity_search(query)\n",
    "print(\"Semantic Search Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
